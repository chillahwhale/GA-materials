{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 15px; height: 80px\">\n",
    "\n",
    "# Quiz 3 In-Class Review\n",
    "\n",
    " _**Authors:** Boom D. (DSI-NYC), Edited by Noelle B. (DSI-DEN)_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** Which method should you use when predicting a $Y$ that is discrete?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- _Regression models continuous $Y$_\n",
    "- _Classification models discrete $Y$_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.** Suppose $Y$ is a binary variable that takes a value of $Y = 1$ if a person is at-risk of heart disease, and $Y = 0$ otherwise. Also let $X_1$ = LDL Cholesterol level and $X_2$ = binary variable for whether or not a person smokes. A scientist decides to construct the following regression model:\n",
    "\n",
    "$$ \\text{log}(\\frac{P(Y = 1)}{1 - P(Y = 1)}) = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 $$\n",
    "\n",
    "After fitting the model with data, the scientist finds that $\\beta_1 = 5.8$\n",
    "\n",
    "What is one appropriate interpretation for the impact of LDL Cholesterol level on the chances of developing heart-disease?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T19:38:27.529630Z",
     "start_time": "2019-07-03T19:38:27.501004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330.2995599096486"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.exp(5.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_For every 1 unit increase in $X_1$, the patient is 330.3 times as likely to be at-risk of heart disease given everything else is held constant._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.** $k$-Nearest Neighbors ($k$NN) is a classification algorithm where $k$ is a hyperparameter. Briefly state what $k$ represents and its role in how the $k$NN algorithm works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- _$k$ is the hyperparameter that controls how many of the closest neighbors we are going to look at._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Metrics: Confusion Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is 2190 and an evil dictator has decided that the justice system should be completely automated by a classification algorithm of his own design that decides whether someone is guilty. Out of 100,000 people sampled, his model has made the following results:\n",
    "- 63,000 truly guilty people were predicted to be guilty\n",
    "- 27,000 truly innocent people were predicted to be guilty\n",
    "- 3,000 truly guilty people were predicted to be innocent\n",
    "- 7,000 truly innocent people were predicted to be innocent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.** Identify the \"positive\" case in this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Positive case : Guilty_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5.** State the number of **false positive** and **false negative** predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- _FP : 27,000_\n",
    "- _FN : 3,000_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6.** Calculate the following metrics\n",
    "    - Accuracy Rate\n",
    "    - Misclassification Rate\n",
    "    - Sensitivity\n",
    "    - Specificity\n",
    "    - Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy : 1-(FP+FN)/ALL = 1-30,000/100,000 = 0.7\n",
    "- Misclassification : (FP+FN)/ALL = 30,000/100,000 = 0.3\n",
    "- Sensitivity : TP/P = TP/(TP + FN) = 63,000/(63,000+3,000) = 63,000/66,000\n",
    "- Specificity : TN/N = TN/(TN + FP) = 7000/(7000+27,000) = 7000/34000\n",
    "- Precision : TP/(TP + FP) = 63,000/(63,000+27,000) = 63,000/90,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Metrics: AUC ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that\n",
    "- Sensitivity : Out of all the Y = 1 observations, how many did we correctly identify?\n",
    "- Specificity : Out of all the Y = 0 observations, how many did we correctly Identify?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7.** Which of these is also known as the True Positive Rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Sensitivity_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8.** If we predict $Y = 1$ for all observations, what happens to:\n",
    "- Sensitivity\n",
    "- Specificity\n",
    "- False Positive Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- _Sensitivity => Increases_\n",
    "- _Specificity => Decreases_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9. (True/False)** The Receiver Operator Characteristic (ROC) curve shows the trade-off between the True Positive Rate and False Positive Rate. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True: _Sensitivity vs. 1 - Specificity_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* If you need a visual for how the ROC curve is constructed from the data, check this out: http://mlwiki.org/index.php/ROC_Analysis#Example_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10.** What range of values can AUC ROC scores take on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_0 to 1_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11.** How would you handle a case where $0 \\le AUC ROC < 0.5$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Terrible model? Invert your target class variables (0s to 1s and vice versa)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12.** A student is trying to optimize a model by tuning hyperparameters with `GridSearchCV()`. She runs the following code to do so.\n",
    "\n",
    "```python\n",
    "params = {'C':       [0.01, 0.02, 0.1, 1, 10, 50, 100],\n",
    "          'penalty': ['l1', 'l2']}\n",
    "logit = GridSearchCV(LogisticRegression(), cv=5, param_grid=params)\n",
    "logit.fit(X_train, y_train)\n",
    "C_optimal = logit.best_params_['C']\n",
    "```\n",
    "How many model fit simulations does the above code run behind the scenes before arriving at the optimal hyperparameter combinations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T20:07:05.565834Z",
     "start_time": "2019-07-03T20:07:05.551365Z"
    }
   },
   "source": [
    "_$7x2x5$ = 70 model fits_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13.** Define the following terms:\n",
    "    - Stemming\n",
    "    - Lemmatization\n",
    "    - Tokenization\n",
    "    - Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stemming: Removing the suffix to get word to root word\n",
    "- Lemmatization: Remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma [(source)](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html)\n",
    "- Tokenization: The process of breaking a stream of text up into words, phrases, symbols, or other meaningful elements called tokens [(source)](https://www.quora.com/NLP-What-does-it-mean-Tokenizing)\n",
    "- Stop Words: A commonly used word that will likely have no significant impact on your NLP model and should be removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q14.** Briefly discuss (preferably with an example case) why it may not always be optimal to always tokenize a string into single words only, i.e. why `ngram_range = (1,1)` is not always ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Two word phrases, such as \"not bad\", have different meaning as opposed to being separate  words._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15.** Briefly explain the adjustment `TFIDFVectorizer()` makes to `CountVectorizer()` and describe why we may sometimes prefer TFIDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CountVectorizer : Breaks a document into unique terms and makes a vector of counts from that document.\n",
    "- TFIDFVectorizer : Some calculation that considers the number of times a term is used in the entire corpus, as well as the document. TFIDF considers the corpus holistically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *max_df : if a word appears over a certain percent of documents, exclude the word*\n",
    "- *min_df : a word must appear in at least a certain number of documents to be included in the vectorizer*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 15px; height: 80px\">\n",
    "\n",
    "# Week 11 Review - Solutions\n",
    "\n",
    " _**Author:** Noelle B. (DSI-DEN)_\n",
    "\n",
    "---\n",
    "We will review the learning objectives of each lesson this week and answer questions related to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11.01 Introduction to Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the general structure of a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** What is the general structure of a neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Neural networks are comprised of an input layer, hidden layers, and an output layer. Each layer is comprised of a number of nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define all of the common vocabulary associated with deep learning (Neuron, weight, bias, hidden layer, activation function, learning rate, epoch, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.** Define `neuron`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Neurons are the weights, bias term and activation function. NNs can have various hidden layers and each hidden layer can have various neurons. Each neuron has their own unique set of weights and bias term and potentially unique activation function in order to arrive at a single value that represents some kind of combination of all the fed in features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.** Define `weight`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Values applied to features as they flow through the network to contribute to interaction. Weights are randomly initialized and adjusted according to gradient decent on our loss function. The weights function similar to coefficients in a linear or logistic regression in which the weights multiply the original value in order to affect how much each feature contributes to the interaction term that results from the activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.** Define `bias`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Constant values that are added in to each neuron. These are also adjusted the same way the weights are, however they exist on their own and do not weight any other value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5.** Define `hidden layer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "1 or more neurons that sit in-between our input layer (original features) and our output layer (predictive function) that are responsible for transforming the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6.** Define `activation function`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "A function on the neuron that takes in the sum of all features after their weights have been applied plus the Bias term and returns a new value that will be used as a feature in the next layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7.** Define `Learning Rate`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**    \n",
    "How large the steps are that we take when moving through our loss function in order to increase/decrease weights in order to decrease total loss. (Same as gradient Descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8.** Define `epoch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "When our full set of training data fully forward and back propagates through our network.\n",
    "- Feed the data through the network.\n",
    "- Calculate the errors.\n",
    "- Propagate backwards to adjust network to better fit the data via found errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand forward and backward propogation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9.** Briefly describe forward propogation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Forward propagation is the process of data flowing through the network in order to arrive at a predicted value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10.** Briefly describe backward propogation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Backward Propagation is the act of optimizing a network be working backwards through it, starting with the errors calculate and identifying the points in the network (weights or nodes) that are contributing most to the error and adjusting them accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11.02 Introduction to Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a neural network from scratch using keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11.** Generate a basic neural network for a regression problem in keras using the generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# data\n",
    "X, y = make_regression(n_samples=10000, n_features=20, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2021)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/5\n",
      "7500/7500 [==============================] - 1s 101us/sample - loss: 39539.6856 - mae: 158.8467 - val_loss: 41404.9202 - val_mae: 163.9947\n",
      "Epoch 2/5\n",
      "7500/7500 [==============================] - 0s 9us/sample - loss: 39484.5990 - mae: 158.7350 - val_loss: 41345.8838 - val_mae: 163.8770\n",
      "Epoch 3/5\n",
      "7500/7500 [==============================] - 0s 8us/sample - loss: 39425.2211 - mae: 158.6145 - val_loss: 41281.1571 - val_mae: 163.7483\n",
      "Epoch 4/5\n",
      "7500/7500 [==============================] - 0s 8us/sample - loss: 39359.4748 - mae: 158.4811 - val_loss: 41206.4521 - val_mae: 163.5993\n",
      "Epoch 5/5\n",
      "7500/7500 [==============================] - 0s 8us/sample - loss: 39282.5156 - mae: 158.3238 - val_loss: 41119.5101 - val_mae: 163.4265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x137cbae10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer\n",
    "model = Sequential()\n",
    "model.add(Dense(32, \n",
    "                input_shape=(20,),\n",
    "                activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "model.fit(X_train_sc, y_train, validation_data=(X_test_sc, y_test), epochs=5, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the differences in creating regression, binary classification, and multi-class classification ANN models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12.** Which activation function should we use for the output layer of a regression NN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Linear/identity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13.** Which activation function should we use for the output layer of a binary classification NN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q14.** Which activation function should we use for the output layer of a multi-class classification NN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize model training with matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15.** Using the neural network below, visualize the training and testing loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# data\n",
    "X, y = make_classification(n_samples=10_000, n_features=20, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2021)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32,\n",
    "                input_shape=(20,),\n",
    "                activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', metrics=['acc'], optimizer='adam')\n",
    "\n",
    "history = model.fit(X_train_sc, y_train, validation_data=(X_test_sc, y_test), epochs=20, batch_size=512, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# answer\n",
    "plt.plot(history.history['loss'], label='Train loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11.03 Deep Learning Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain how the three deep learning regularization techniques work (L1/L2 regularization, Dropout, Early stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q16.** Describe L1/L2 regularization for deep learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "- Incorporating either LASSO or Ridge regularization into back propagation is as simple as adding the regularization term to the loss function (ok, not very simple at all when you look at the math)\n",
    "- L1 typically isn't used in NNs.\n",
    "- L2 is much more popular and sometimes referred to as \"weight decay\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q17.** Describe dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "- The process of randomly removing nodes in training epochs to see how it affects the model. A NN with densly connected layers will have the tendency to overfit so we can utilize drop out in order better understand if nodes should be removed or kept. (Similar to how Random Forests reduce variance and overfitting.)\n",
    "- Dropouts can occur at any epoch and the models \"constant fear\" of loosing a node at any time prevents the over adjustment of a weight for an epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q18.** Describe early stopping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Answer:**   \n",
    "Compares how much the loss function is changes and stops the algorithm once it hits the point where the loss function starts to go up. This is done with the assumption that the first minimum that was hit it the global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement these techniques in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q19.** Using the data below, build a binary classification neural network in kearas using an early stopping technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# data\n",
    "X, y = make_classification(n_samples=10_000, n_features=20, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2021)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 1s 141us/sample - loss: 0.4754 - acc: 0.7913 - val_loss: 0.3569 - val_acc: 0.8696\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 1s 71us/sample - loss: 0.3237 - acc: 0.8780 - val_loss: 0.2998 - val_acc: 0.8872\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 1s 71us/sample - loss: 0.2932 - acc: 0.8895 - val_loss: 0.2862 - val_acc: 0.8940\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 1s 70us/sample - loss: 0.2793 - acc: 0.8977 - val_loss: 0.2757 - val_acc: 0.9012\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 1s 71us/sample - loss: 0.2671 - acc: 0.9063 - val_loss: 0.2653 - val_acc: 0.9036\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 1s 76us/sample - loss: 0.2567 - acc: 0.9161 - val_loss: 0.2554 - val_acc: 0.9092\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 1s 72us/sample - loss: 0.2483 - acc: 0.9223 - val_loss: 0.2494 - val_acc: 0.9156\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 1s 76us/sample - loss: 0.2427 - acc: 0.9259 - val_loss: 0.2444 - val_acc: 0.9204\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 1s 81us/sample - loss: 0.2386 - acc: 0.9293 - val_loss: 0.2433 - val_acc: 0.9212\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 1s 78us/sample - loss: 0.2357 - acc: 0.9315 - val_loss: 0.2412 - val_acc: 0.9216\n"
     ]
    }
   ],
   "source": [
    "# answer:\n",
    "model_es = Sequential()\n",
    "\n",
    "n_input = X_train_sc.shape[1]\n",
    "\n",
    "model_es.add(Dense(n_hidden, input_dim=n_input, activation='relu'))\n",
    "model_es.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_es.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "history_es = model_es.fit(\n",
    "    X_train_sc,\n",
    "    y_train,\n",
    "    validation_data=(X_test_sc, y_test),\n",
    "    epochs=10,\n",
    "    batch_size=None,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q20.** Using the data below, build a binary classification neural network in keras using a dropout technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# data\n",
    "X, y = make_classification(n_samples=10_000, n_features=20, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2021)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 2s 232us/sample - loss: 0.6889 - acc: 0.6175 - val_loss: 0.4745 - val_acc: 0.8284\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 1s 73us/sample - loss: 0.4626 - acc: 0.7907 - val_loss: 0.3504 - val_acc: 0.8720\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 1s 67us/sample - loss: 0.3797 - acc: 0.8424 - val_loss: 0.3104 - val_acc: 0.8836\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 0s 66us/sample - loss: 0.3560 - acc: 0.8588 - val_loss: 0.2972 - val_acc: 0.8876\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 1s 70us/sample - loss: 0.3359 - acc: 0.8715 - val_loss: 0.2905 - val_acc: 0.8920\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 1s 70us/sample - loss: 0.3235 - acc: 0.8753 - val_loss: 0.2865 - val_acc: 0.8952\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 0s 65us/sample - loss: 0.3179 - acc: 0.8820 - val_loss: 0.2812 - val_acc: 0.8976\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 0s 66us/sample - loss: 0.3097 - acc: 0.8860 - val_loss: 0.2778 - val_acc: 0.8984\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 0s 65us/sample - loss: 0.3123 - acc: 0.8855 - val_loss: 0.2742 - val_acc: 0.9028\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 1s 68us/sample - loss: 0.3000 - acc: 0.8939 - val_loss: 0.2706 - val_acc: 0.9028\n"
     ]
    }
   ],
   "source": [
    "# answer:\n",
    "model_dropout = Sequential()\n",
    "\n",
    "\n",
    "n_input = X_train_sc.shape[1]\n",
    "n_hidden = n_input\n",
    "\n",
    "model_dropout.add(Dense(n_hidden, input_dim=n_input, activation='relu'))\n",
    "model_dropout.add(Dropout(0.5))\n",
    "model_dropout.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_dropout.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "history_dropout = model_dropout.fit(\n",
    "    X_train_sc,\n",
    "    y_train,\n",
    "    validation_data=(X_test_sc, y_test), \n",
    "    epochs=10,\n",
    "    batch_size=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11.04 Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify use cases for convolutional neural networks and when they are superior to other neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q21.** Identify use cases for CNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Convolutional NNs consider features related to one another via proximity, this makes them great for assessing pictures because they are able to break down a picture the way humans do, by focusing one specific areas of the photo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe convolutional and pooling layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q22.** What are convolutional layers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Answer:**  \n",
    "\"A convolution is the simple application of a filter to an input that results in an activation. Repeated application of the same filter to an input results in a map of activations called a feature map, indicating the locations and strength of a detected feature in an input, such as an image.\" [source](https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q23.** What are pooling layers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Answer:**  \n",
    "Pooling layers allow us to compress output from the convolution layers.\n",
    "- Max Pooling is typically the tactic used in the pooling layer. This identifies and takes the strongest/most important info for retention.\n",
    "- Pooling is done independently across channels. (Each \"node\" has its own unique pooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define padding and filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q24.** Define padding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Answer:**  \n",
    "Given that the way edges flow over a picture an aspect of padding can be added.  This is essentially adding boarding cells of neutral values around a picture so that pixels that are in corners or along edges can be considered more often\n",
    "- In the event there is something important in the corner of an image, without having padding that corner may only be considered once.\n",
    "- Typically we as humans gravitate our focus towards the center of an image and work outward, they further away from the center objects are in a picture the less we notice them, think about what happens in the corners of pictures.  Its typically not a place you consciously look at when looking at a picture, padding tries to combat NNs from picking up on this same habit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q25.** Define filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Answer:**  \n",
    "Each filter can detect one type of feature in an image (like vertical edges)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit CNNs in Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q26.** Using the data below, fit a CNN in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# For reproducibility\n",
    "np.random.seed(2021)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.datasets import mnist\n",
    " \n",
    "# Load pre-shuffled MNIST data into train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "y_train = utils.to_categorical(y_train, 10)\n",
    "y_test = utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 17s 279us/sample - loss: 1.6877 - accuracy: 0.8486 - val_loss: 0.2803 - val_accuracy: 0.9427\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 18s 302us/sample - loss: 0.2107 - accuracy: 0.9524 - val_loss: 0.1762 - val_accuracy: 0.9600\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 20s 340us/sample - loss: 0.1267 - accuracy: 0.9677 - val_loss: 0.1468 - val_accuracy: 0.9674\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 20s 341us/sample - loss: 0.0872 - accuracy: 0.9767 - val_loss: 0.1305 - val_accuracy: 0.9704\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 19s 325us/sample - loss: 0.0652 - accuracy: 0.9814 - val_loss: 0.1132 - val_accuracy: 0.9743\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 17s 278us/sample - loss: 0.0476 - accuracy: 0.9856 - val_loss: 0.1154 - val_accuracy: 0.9731\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 18s 301us/sample - loss: 0.0363 - accuracy: 0.9887 - val_loss: 0.1119 - val_accuracy: 0.9748\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 19s 312us/sample - loss: 0.0275 - accuracy: 0.9914 - val_loss: 0.1008 - val_accuracy: 0.9768\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 17s 280us/sample - loss: 0.0250 - accuracy: 0.9917 - val_loss: 0.1079 - val_accuracy: 0.9768\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 17s 287us/sample - loss: 0.0207 - accuracy: 0.9929 - val_loss: 0.0981 - val_accuracy: 0.9799\n"
     ]
    }
   ],
   "source": [
    "# answer:\n",
    "cnn_model = Sequential()\n",
    "\n",
    "cnn_model.add(Conv2D(filters=6,            \n",
    "                     kernel_size=(3, 3),     \n",
    "                     activation='relu', \n",
    "                     input_shape=(28, 28, 1)))\n",
    "\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "\n",
    "cnn_model.add(Conv2D(16,\n",
    "                     kernel_size = (3, 3),\n",
    "                     activation='relu'))\n",
    "\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "cnn_model.add(Flatten())\n",
    "\n",
    "cnn_model.add(Dense(128, activation='relu'))\n",
    "\n",
    "cnn_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "cnn_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = cnn_model.fit(X_train,\n",
    "                        y_train,\n",
    "                        batch_size=256,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        epochs=10,\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand how edge detection works in CNNs. (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q27.** (Optional) How does edge detection work in a CNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "- An edge is identified by discontinuity in an image typically in color.\n",
    "- When we pass our weights window over a panel of data in a picture we transform and map the image into smaller dimensions.\n",
    "- Our Window will have conflicting/balanced weights on each side of it, one side very positive and one side very negative. If there is a significant difference in color/greyscale (what we would interpret as a edge). When the window passes over it, the weights applied on each side of the window will no longer neutral out and instead result in a significant positive or negative value indicating there is a drastic difference in shading from one side of the window to another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11.05 Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design, train and evaluate an RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q28.** Briefly describe how an RNN model works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "\"RNNs can take one or more input vectors and produce one or more output vectors and the output(s) are influenced not just by weights applied on inputs like a regular NN, but also by a “hidden” state vector representing the context based on prior input(s)/output(s). So, the same input could produce a different output depending on previous inputs in the series.\" [source](https://towardsdatascience.com/recurrent-neural-networks-d4642c9bc7ce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q29.** What are some use cases of RNNs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Natural language processing, time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11.06 GridSearch with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn how to use keras's scikit_learn wrappers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q30.** What do kera's scikit_learn wrappers help with?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "These allow us to use sklearn tools such as gridseach with a neural network built in keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use GridSearchCV to tune a keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q31.** Use the given data to tune a keras regression model using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "X, y = make_regression(n_samples=10_000, n_features=20, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1503.1744921223958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs': 50, 'layer_one_neurons': 32, 'layer_two_neurons': 32}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer:\n",
    "def model_func(layer_one_neurons=32, layer_two_neurons=32):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(layer_one_neurons, activation='relu', input_shape=(20,)))\n",
    "    \n",
    "    model.add(Dense(layer_two_neurons, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation=None))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "nn = KerasRegressor(build_fn=model_func, batch_size=512, verbose=0)\n",
    "\n",
    "params = {\n",
    "    'epochs': [50],\n",
    "    'layer_one_neurons': [32],\n",
    "    'layer_two_neurons': [32]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(nn, param_grid=params, cv=2)\n",
    "gs.fit(X_train_sc, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

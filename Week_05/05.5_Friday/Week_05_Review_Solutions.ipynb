{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 15px; height: 80px\">\n",
    "\n",
    "# Week 5 Review - Solutions\n",
    "\n",
    " _**Author:** Noelle B. (DSI-DEN)_\n",
    "\n",
    "---\n",
    "We will review the learning objectives of each lesson this week and answer questions related to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.01 Intro to HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a HTML document from scratch & Describe the most common HTML tags and their usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** What does this tag mean: `<p></p>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Paragraph tag, signifies the start of a paragraph of text or other elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.** What does this tag mean: `<ul></ul>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Unordered list, creates a bulleted list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.** What does this tag mean: `<th></th>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Table header, specifies the header row in a table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.** What does this tag mean: `<body></body>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Body tag, specifies the body of the webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain how CSS can be used to modify the display of HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5.** What does `CSS` stand for? What does `HTML` stand for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "CSS: Cascading Style Sheets  \n",
    "HTML: Hypertext Markup Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6.** What is the difference between CSS and HTML?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "CSS describes how HTML elements are displayed on the webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.02 BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7.** Define Webscraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Webscraping is the process of extracting data from a website using code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the requests library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8.** Use the requests library to create a request for the following URL. What status code do you get and what does this mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "url = 'https://www.imdb.com/title/tt0241527/'\n",
    "\n",
    "# Answer:\n",
    "res = requests.get(url)\n",
    "res.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "A status code of 200 means the request was successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Beautiful Soup object & find soup objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9.** Using the following request, create a beautiful soup object and find all table objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = 'https://www.imdb.com/title/tt0241527/'\n",
    "res = requests.get(url)\n",
    "\n",
    "# Answer:\n",
    "soup = BeautifulSoup(res.content, 'lxml')\n",
    "table = soup.find_all('table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create a pandas dataframe from a scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10.** Using the following table scraped from IMDb, create a dataframe of actor name and character name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.imdb.com/title/tt0241527/'\n",
    "res = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(res.content, 'lxml')\n",
    "table = soup.find('table', {'class': 'cast_list'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Richard Harris</td>\n",
       "      <td>Albus Dumbledore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maggie Smith</td>\n",
       "      <td>Professor McGonagall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robbie Coltrane</td>\n",
       "      <td>Hagrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Saunders Triplets</td>\n",
       "      <td>Baby Harry Potter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daniel Radcliffe</td>\n",
       "      <td>Harry Potter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fiona Shaw</td>\n",
       "      <td>Aunt Petunia Dursley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Harry Melling</td>\n",
       "      <td>Dudley Dursley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Richard Griffiths</td>\n",
       "      <td>Uncle Vernon Dursley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Derek Deadman</td>\n",
       "      <td>Bartender in Leaky Cauldron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ian Hart</td>\n",
       "      <td>Professor Quirrell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ben Borowiecki</td>\n",
       "      <td>Diagon Alley Boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Warwick Davis</td>\n",
       "      <td>Goblin Bank Teller /  \\n            Professor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Verne Troyer</td>\n",
       "      <td>Griphook \\n  \\n  \\n  (as Vern Troyer)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>John Hurt</td>\n",
       "      <td>Mr. Ollivander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Richard Bremmer</td>\n",
       "      <td>He Who Must Not Be Named</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name                                          character\n",
       "0      Richard Harris                                   Albus Dumbledore\n",
       "1        Maggie Smith                               Professor McGonagall\n",
       "2     Robbie Coltrane                                             Hagrid\n",
       "3   Saunders Triplets                                  Baby Harry Potter\n",
       "4    Daniel Radcliffe                                       Harry Potter\n",
       "5          Fiona Shaw                               Aunt Petunia Dursley\n",
       "6       Harry Melling                                     Dudley Dursley\n",
       "7   Richard Griffiths                               Uncle Vernon Dursley\n",
       "8       Derek Deadman                        Bartender in Leaky Cauldron\n",
       "9            Ian Hart                                 Professor Quirrell\n",
       "10     Ben Borowiecki                                   Diagon Alley Boy\n",
       "11      Warwick Davis  Goblin Bank Teller /  \\n            Professor ...\n",
       "12       Verne Troyer              Griphook \\n  \\n  \\n  (as Vern Troyer)\n",
       "13          John Hurt                                     Mr. Ollivander\n",
       "14    Richard Bremmer                           He Who Must Not Be Named"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer:\n",
    "cast_list = []\n",
    "\n",
    "for row in table.find_all('tr')[1:]:\n",
    "    cast = {}\n",
    "    cast['name'] = row.find_all('a')[1].text.strip()\n",
    "    cast['character'] = row.find('td', {'class': 'character'}).text.strip()\n",
    "    \n",
    "    cast_list.append(cast)\n",
    "    \n",
    "pd.DataFrame(cast_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.03 NLP I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and implement tokenizing, lemmatizing, and stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11.** Define `tokenizing`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:** \n",
    "Tokenizing is the process of splitting text into smaller chunks/tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12.** Define `lemmatizing`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Answer:**  \n",
    "Lemmatizing is the process of getting words to their 'lemma,' or their root form that is a dictionary word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13.** Define `stemming`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Stemming is the process of returning a root/base of a word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe what RegEx does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q14.** What is RegEx and what does it do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Regular expressions allow you to segment text by defining a search pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15.** Apply a simple sentiment analysis using the following positive and negative words on the Google review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = ['delight', 'good', 'great', 'awesome', 'tremendous', 'fabulous', 'amazing', 'stellar', 'best', 'love']\n",
    "negative_words = ['garbage', 'sad', 'trash', 'ugly', 'bad', 'disgusting', 'terrible', 'gross', 'worst', 'awful']\n",
    "\n",
    "review = 'Waited half an hour for my food. Normally the team is strong but i noticed the manager barely helping hiding in the back while over 20 people stood waiting for food while they continued to take orders. Doordash and the delivery services didnt help as there were massive orders backing the place up. Worst experience ever at a fast food place.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Code from global lesson 5.03\n",
    "def simple_sentiment(text):\n",
    "    # Instantiate tokenizer.\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    \n",
    "    # Tokenize text.\n",
    "    tokens = tokenizer.tokenize(text.lower())\n",
    "    \n",
    "    # Instantiate stemmer.\n",
    "    p_stemmer = PorterStemmer()\n",
    "    \n",
    "    # Stem words.\n",
    "    stemmed_words = [p_stemmer.stem(i) for i in tokens]\n",
    "    \n",
    "    # Stem our positive/negative words.\n",
    "    positive_stems = [p_stemmer.stem(i) for i in positive_words]\n",
    "    negative_stems = [p_stemmer.stem(i) for i in negative_words]\n",
    "\n",
    "    # Count \"positive\" words.\n",
    "    positive_count = sum([1 for i in stemmed_words if i in positive_stems])\n",
    "    \n",
    "    # Count \"negative\" words\n",
    "    negative_count = sum([1 for i in stemmed_words if i in negative_stems])\n",
    "    \n",
    "    # Calculate Sentiment Percentage \n",
    "    # (Positive Count - Negative Count) / (Total Count)\n",
    "\n",
    "    return round((positive_count - negative_count) / len(tokens), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.02"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_sentiment(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q16.** What are some steps that you should take to pre-process text data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Answer:**   \n",
    "- Tokenize\n",
    "- Lemmatize or stem\n",
    "- Remove stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.04 NLP II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features from unstructured text by fitting and transforming with CountVectorizer and TfidfVectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q17.** Vectorize the following data using CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "tweets = pd.read_csv('./data/trump_tweets.csv')\n",
    "tweets = tweets['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00pm</th>\n",
       "      <th>05c14uxy2b</th>\n",
       "      <th>09bac03rx6</th>\n",
       "      <th>0cyrjl1yoj</th>\n",
       "      <th>0dtxsagkz1</th>\n",
       "      <th>0zhugiepot</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>...</th>\n",
       "      <th>zcqc7nzmme</th>\n",
       "      <th>zdj3lyo76h</th>\n",
       "      <th>zelensky</th>\n",
       "      <th>zlldo4gtij</th>\n",
       "      <th>zone</th>\n",
       "      <th>zpqcjgc4xh</th>\n",
       "      <th>zqhadcikqg</th>\n",
       "      <th>zryfqxatin</th>\n",
       "      <th>ztcsrcqjcn</th>\n",
       "      <th>zucker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1767 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  00pm  05c14uxy2b  09bac03rx6  0cyrjl1yoj  0dtxsagkz1  0zhugiepot  \\\n",
       "0   0    0     0           0           0           0           0           0   \n",
       "1   0    0     0           0           0           0           0           0   \n",
       "2   0    0     0           0           0           0           0           0   \n",
       "3   0    0     0           0           0           0           0           0   \n",
       "4   0    0     0           0           0           0           0           0   \n",
       "\n",
       "   10  100  ...  zcqc7nzmme  zdj3lyo76h  zelensky  zlldo4gtij  zone  \\\n",
       "0   0    0  ...           0           0         0           0     0   \n",
       "1   0    0  ...           0           0         0           0     0   \n",
       "2   0    0  ...           0           0         0           0     0   \n",
       "3   0    0  ...           0           0         0           0     0   \n",
       "4   0    0  ...           0           0         0           0     0   \n",
       "\n",
       "   zpqcjgc4xh  zqhadcikqg  zryfqxatin  ztcsrcqjcn  zucker  \n",
       "0           0           0           0           0       0  \n",
       "1           0           0           0           0       0  \n",
       "2           0           0           0           0       0  \n",
       "3           0           0           0           0       0  \n",
       "4           0           0           0           0       0  \n",
       "\n",
       "[5 rows x 1767 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer\n",
    "# code from global lesson 5.04\n",
    "cvec = CountVectorizer()\n",
    "cvec.fit(tweets)\n",
    "cv_tweets = cvec.transform(tweets)\n",
    "cv_tweets_df = pd.DataFrame(cv_tweets.toarray(),\n",
    "                          columns=cvec.get_feature_names())\n",
    "cv_tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q18.** Vectorize the following data using TfidfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tweets = pd.read_csv('./data/trump_tweets.csv')\n",
    "tweets = tweets['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00pm</th>\n",
       "      <th>05c14uxy2b</th>\n",
       "      <th>09bac03rx6</th>\n",
       "      <th>0cyrjl1yoj</th>\n",
       "      <th>0dtxsagkz1</th>\n",
       "      <th>0zhugiepot</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>...</th>\n",
       "      <th>zcqc7nzmme</th>\n",
       "      <th>zdj3lyo76h</th>\n",
       "      <th>zelensky</th>\n",
       "      <th>zlldo4gtij</th>\n",
       "      <th>zone</th>\n",
       "      <th>zpqcjgc4xh</th>\n",
       "      <th>zqhadcikqg</th>\n",
       "      <th>zryfqxatin</th>\n",
       "      <th>ztcsrcqjcn</th>\n",
       "      <th>zucker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1767 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  00pm  05c14uxy2b  09bac03rx6  0cyrjl1yoj  0dtxsagkz1  0zhugiepot  \\\n",
       "0  0.0  0.0   0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1  0.0  0.0   0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2  0.0  0.0   0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3  0.0  0.0   0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4  0.0  0.0   0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "    10  100  ...  zcqc7nzmme  zdj3lyo76h  zelensky  zlldo4gtij  zone  \\\n",
       "0  0.0  0.0  ...         0.0         0.0       0.0         0.0   0.0   \n",
       "1  0.0  0.0  ...         0.0         0.0       0.0         0.0   0.0   \n",
       "2  0.0  0.0  ...         0.0         0.0       0.0         0.0   0.0   \n",
       "3  0.0  0.0  ...         0.0         0.0       0.0         0.0   0.0   \n",
       "4  0.0  0.0  ...         0.0         0.0       0.0         0.0   0.0   \n",
       "\n",
       "   zpqcjgc4xh  zqhadcikqg  zryfqxatin  ztcsrcqjcn  zucker  \n",
       "0         0.0         0.0         0.0         0.0     0.0  \n",
       "1         0.0         0.0         0.0         0.0     0.0  \n",
       "2         0.0         0.0         0.0         0.0     0.0  \n",
       "3         0.0         0.0         0.0         0.0     0.0  \n",
       "4         0.0         0.0         0.0         0.0     0.0  \n",
       "\n",
       "[5 rows x 1767 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer\n",
    "# code from global lesson 5.04\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(tweets)\n",
    "tf_tweets = tfidf.transform(tweets)\n",
    "tf_tweets_df = pd.DataFrame(tf_tweets.toarray(),\n",
    "                          columns=tfidf.get_feature_names())\n",
    "tf_tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe how CountVectorizers and TF-IDFVectorizers work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q19.** How do `TF-IDF Vectorizers` work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Answer:**  \n",
    "TF-IDF (term frequency - inverse document frequency) Vectorizer \"assigns each word in a document a number that is proportional to its frequency in the document and inversely proportional to the number of documents in which it occurs. Very common words, such as “a” or “the”, thereby receive heavily discounted tf-idf scores, in contrast to words that are very specific to the document in question. The result is a matrix of tf-idf scores with one row per document and as many columns as there are different words in the dataset.\" [source](https://buhrmann.github.io/tfidf-analysis.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q20.** How do `Count Vectorizers` work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Count Vectorizers work by returning an integer count of how often each word appears in the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand stop_words, max_features, min_df, max_df, and ngram_range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q21.** What are `stop words`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Answer:**  \n",
    "Stop words are words that do not add anything to our analysis and we often want to remove. Examples include 'a', 'the', 'and', etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q22.** What does adjusting `max_features` in CountVectorizer do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "This restricts the maximum number of features (only top n most popular words) to be used. This solves the problem of having extremely large results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q23.** What does adjusting `min_df` in CountVectorizer do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "This sets the minimum number of documents that a word must occur in to be included as a feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q24.** What does adjusting `max_df` in CountVectorizer do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "This only considers words that occur in at most some percentage of documents to be used as features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q25.** What does adjusting `ngram_range` in CountVectorizer do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "This determines what $n$-grams should be considered as features. For example, if you set ngram_range=(1,2) this captures both single words and pairs of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement CountVectorizer and TfidfVectorizer in a spam classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q26.** Use CountVectorizer along with a Logistic Regression model to predict whether the retweet count will be greater than 18,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "tweets = pd.read_csv('./data/trump_tweets.csv')\n",
    "tweets['target'] = np.where(tweets['retweet_count'] > 18000, 1, 0)\n",
    "\n",
    "X = tweets['text']\n",
    "y = tweets['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9812734082397003\n",
      "Testing Score: 0.6555555555555556\n"
     ]
    }
   ],
   "source": [
    "# Answer\n",
    "cvec = CountVectorizer()\n",
    "X_train = cvec.fit_transform(X_train)\n",
    "X_test = cvec.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(f'Training Score: {lr.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {lr.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q27.** Use TfidfVectorizer along with a Logistic Regression model to predict whether the retweet count will be greater than 18,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "tweets = pd.read_csv('./data/trump_tweets.csv')\n",
    "tweets['target'] = np.where(tweets['retweet_count'] > 18000, 1, 0)\n",
    "\n",
    "X = tweets['text']\n",
    "y = tweets['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9588014981273408\n",
      "Testing Score: 0.6222222222222222\n"
     ]
    }
   ],
   "source": [
    "# Answer\n",
    "tvec = TfidfVectorizer()\n",
    "X_train = tvec.fit_transform(X_train)\n",
    "X_test = tvec.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(f'Training Score: {lr.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {lr.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use GridSearchCV and Pipeline with CountVectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q28.** Use CountVectorizer along with a Logistic Regression model in a pipeline to predict whether the retweet count will be greater than 18,000. Search over the following values of hyperparameters:\n",
    "- Maximum number of features fit: 3000, 4000\n",
    "- Minimum number of documents needed to include token: 2, 3, 4\n",
    "- Maximum number of documents needed to include token: 85%, 90%, 95%\n",
    "- Check (individual tokens) and also check (individual tokens and 2-grams)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "tweets = pd.read_csv('./data/trump_tweets.csv')\n",
    "tweets['target'] = np.where(tweets['retweet_count'] > 18000, 1, 0)\n",
    "\n",
    "X = tweets['text']\n",
    "y = tweets['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6591760299625468\n",
      "Training Score: 0.9662921348314607\n",
      "Testing Score: 0.6222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noellebrown/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Answer\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr', LogisticRegression(solver = 'lbfgs'))\n",
    "])\n",
    "\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [3_000, 4_000],\n",
    "    'cvec__min_df': [2, 3, 4],\n",
    "    'cvec__max_df': [.85, .9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=5)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "\n",
    "gs_model = gs.best_estimator_\n",
    "\n",
    "print(f'Training Score: {gs_model.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {gs_model.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.05 API Integration & Consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain what an application program interface (API) is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q29.** What is an API?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "An application programming interface (API) is broadly a pattern of programming that allows a programmer to solve a task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain the very basics of HTTP and how it's used to get data from the web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q30.** Broadly speaking, what is HTTP and how is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "HTTP stands for hyptertext transfer protocol. It is a set of rules for passing data around the web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the requests library to submit HTTP requests from Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q31.** Submit an HTTP request to get information about a Pokemon of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://pokeapi.co/api/v2/pokemon/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sand-attack', 'url': 'https://pokeapi.co/api/v2/move/28/'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer:\n",
    "import requests\n",
    "\n",
    "# Make request\n",
    "res = requests.get(base_url + \"eevee\")\n",
    "res.json()['moves'][0]['move']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a free Python API to access real-time stock prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q32.** Using the free [open-notify API](http://api.open-notify.org/), get the number of people in space right now.\n",
    "\n",
    "*Note: API found from this [source](https://www.dataquest.io/blog/python-api-tutorial/).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'people': [{'name': 'Andrew Morgan', 'craft': 'ISS'},\n",
       "  {'name': 'Oleg Skripochka', 'craft': 'ISS'},\n",
       "  {'name': 'Jessica Meir', 'craft': 'ISS'},\n",
       "  {'name': 'Chris Cassidy', 'craft': 'ISS'},\n",
       "  {'name': 'Anatoly Ivanishin', 'craft': 'ISS'},\n",
       "  {'name': 'Ivan Vagner', 'craft': 'ISS'}],\n",
       " 'message': 'success',\n",
       " 'number': 6}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://api.open-notify.org/astros.json'\n",
    "\n",
    "# Answer:\n",
    "import requests\n",
    "\n",
    "res = requests.get(url)\n",
    "res.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.06 Introduction to AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properly define cloud computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q33.** What is cloud computing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Cloud computing is computing on a server that is maintained by someone else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain and identify the need for cloud computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q34.** Why do we need cloud computing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Powerful computers are expensive and maintaining servers is cumbersome. Cloud computing services allow us to access servers that would be way to expensive if we bought them on our own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to a remote server from the command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q35.** What is the protocol we used to connect to our server from the command line? Bonus: what is the command that we used to do this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "SSH: Secure shell protocol  \n",
    "Bonus: *ssh -i /path/to/key.pem ubuntu.ec2-ip-address.amazonaws.com*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate and configure a remote server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q36.** True/False: it is okay to put your code on GitHub that has your security key on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "False! This is a terrible idea and will typically get flagged by AWS/GitHub pretty quickly telling you to take it down. Someone else could use this key and it could cost you a lot of money. You can read someone's personal account of this [here](https://www.dannyguo.com/blog/i-published-my-aws-secret-key-to-github/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post and retrieve files to and from a remote server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q37.** What should you always do when you are done working on a remote server and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Terminate your instance so you don't accidentally get charged a bunch of money."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

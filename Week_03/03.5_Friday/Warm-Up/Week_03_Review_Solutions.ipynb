{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 15px; height: 80px\">\n",
    "\n",
    "# Week 3 Review - Solutions\n",
    "\n",
    " _**Author:** Noelle B. (DSI-DEN)_\n",
    "\n",
    "---\n",
    "We will review the learning objectives of each lesson this week and answer questions related to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST!!!!\n",
    "# import the data to use for the rest of this review\n",
    "# run this cell\n",
    "import pandas as pd\n",
    "\n",
    "boston = pd.read_csv('data/boston_housing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.06 Ethics & Plagiarism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the General Assembly plagiarism policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** The following is an example of a violation of GA's plagiarism policiy:\n",
    "- Copying words or code without giving credit.\n",
    "What could you do to avoid violating this example in the policy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Give credit in a comment from where you got inspiration for your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify how data science is implemented every day in obvious and non-obvious ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.** Read [this article](https://www.vox.com/recode/2020/3/4/21163743/ai-language-generation-fake-text-gpt2).  \n",
    "How is data science implemented here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "As natural language processing techniques improve, computers are able to generate text that sounds close to human-generated. This encourages us to be wary of the articles that we read and make sure we use NLP techniques ethically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand some of the ethical responsibilities associated with gathering and using data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.** What is the rule of thumb when collecting data? What should you consider before you gather data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Only collect data that is absolutely necessary. Consider the worst case scenario when working with data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify how to improve gathering and using data & constructively scrutinize others’ gathering and using data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.** Consider this fictional scenario:  \n",
    "A gaming company wants to understand trends on how long users spend on the game during various times of the year to determine the best launch date for their next game. Your boss suggests collecting the following user information:\n",
    "- The location of the user\n",
    "- The user's name\n",
    "- The user's email\n",
    "- Time spent on the game\n",
    "- The user's social security number\n",
    "- Days the user logged in  \n",
    "\n",
    "Would you change anything about this suggested data collection? If so, what?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "You probably only need the time spent on the game, and the days the user logged in. Possibly name and email if absolutely necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.01 Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5.** What is modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Modeling is a simplification of reality. It allows us to make educated predictions based on patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate mean squared error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6.** Describe Mean Squared Error in words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Mean squared error is the average of the squared residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7.** Write a function that would calculate the mean squared error given real values and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n",
    "# code from global lesson 3.01\n",
    "def mse(real, preds):\n",
    "    n = len(real)\n",
    "    result = 0\n",
    "    for i in range(n):\n",
    "        result += (real[i] - preds[i])**2\n",
    "    result = result/n\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State the assumptions of a linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8.** State the assumptions of simple linear regression and multiple linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "- Linearity: $Y$ must have an approximately linear relationship with each $X$ variable.\n",
    "- Independence of Errors: Errors (residuals) $\\varepsilon_i$ and $\\varepsilon_j$ must be independent of one another for any $i \\ne j$.\n",
    "- Normality: The errors (residuals) follow a Normal distribution with mean 0.\n",
    "- Equality of Variances: The errors (residuals) should have a roughly consistent pattern, regardless of the value of the $X$ variables. (There should be no discernable relationship between the $X$ variable and the residuals.)\n",
    "- Independence of Predictors (almost always violated at least a little!): The independent variables $X_i$ and $X_j$ must be independent of one another for any $i \\ne j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Be able to interpret the coefficients of a linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9.** You perform a linear regression to predict sales, and you get the following coefficients. Interpret both of them:\n",
    "\n",
    "| Feature | Coefficient |\n",
    "| --- | --- |\n",
    "| Facebook Ads | 3019 |\n",
    "| Podcast Ads | 2187 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "- Facebook Ads: For every one unit increase in Facebook ad spending, we expect Sales to increase by \\$3,019 holding all else constant.  \n",
    "- Podcast Ads: For every one unit increase in Podcast ad spending, we expect Sales to increase by \\$2,187 holding all else constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the difference between simple and multiple linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10.** Describe the difference between a simple linear regression model and a multiple linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "SLR predicts the target using only one feature. MLR predicts the target with more than one feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit, generate predictions from, and evaluate a linear regression model in sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11.** Fit, generate predictions, and evaluate a linear regression model in sklearn for the Boston housing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = boston.drop(columns='MEDV')\n",
    "y = boston['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7341487741330595"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer:\n",
    "lm = LinearRegression()\n",
    "lm.fit(X, y)\n",
    "\n",
    "lm.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.02 Regression Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and implement six regression metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12.** Define the following regression metrics:\n",
    "- Residuals\n",
    "- Mean Absolute Error (MAE)\n",
    "- Sum Squared Error (SSE)\n",
    "- Mean Squared Error (MSE)\n",
    "- Root Mean Squared Error (RMSE)\n",
    "- Coefficient of Determination (R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Answer:**  \n",
    "- Residuals: The difference between the real value and your predicted value\n",
    "- Mean Absolute Error (MAE): The average of the absolute value of the residuals\n",
    "- Sum Squared Error (SSE): The sum of the residuals squared\n",
    "- Mean Squared Error (MSE): The average of the squared residuals\n",
    "- Root Mean Squared Error (RMSE): The square root of the MSE\n",
    "- Coefficient of Determination (R2): The percentage of the variability in the target that can be explained by the x-variables in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13.** What is feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Feature selection is the process of choosing which features should be included in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.03 Bias-Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe error due to bias and error due to variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q14.** What is bias in a model? How can you tell if your model has high bias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Bias is a measure of how simple or underfit the model is. High bias means the model is bad and should be improved by adding variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15.** What is variance in a model? How can you tell if your model has high variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Answer:**  \n",
    "Variance is a measure of how overfit or complicated your model is. High variance means a model does not perform well on new data and should be simplified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define overfitting and underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q16.** What does it mean to say a model is 'overfit'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Answer:**   \n",
    "An overfit model does well on the data it was trained on, but does not do well on new/unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q17.** What does it mean to say a model is 'underfit'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "An underfit model is essentially a bad model - it does not do well on any data. It should be improved by adding complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the relationships among bias and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q18.** What is the common relationship between bias and variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "> **Answer:**  \n",
    "Typically, bias and variance have an inverse relationship. If a model has high variance, it has low bias and vice-versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe and implement methods for reducing bias and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q19.** Your model has high bias. What could you do to try to fix this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Answer:**  \n",
    "Add complexity - add more features, engineer new features, or use a different model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q20.** Your model has high variance. What could you do to try to fix this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Add bias - use less features, regularize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.04 Train-Test-Split and Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe train/test split and cross-validation & explain how these validation techniques differ and why we want to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q21.** What is train/test split and why do we do it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Answer:**  \n",
    "Train/test split splits the data into a training set (about 80% of data) and a testing set (about 20% of data). This allows you to see how well your model performs on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q22.** What is cross validation and why do we do it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "Cross validation allows you to see how well your model performs on unseen data several times. This prevents a good or bad score due to randomness from occurring and gives you more evidence on whether your model is good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into testing and training sets using both train/test split and cross-validation and apply both techniques to score a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q23.** Conduct a linear regression on the Boston housing dataset using train/test split. Score your model on the testing set and the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = boston.drop(columns='MEDV')\n",
    "y = boston['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2 Score:  0.736013519059072\n",
      "Testing R2 Score:  0.7079609674276833\n"
     ]
    }
   ],
   "source": [
    "# Answer:\n",
    "# split into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# instantiate linear regression\n",
    "lm = LinearRegression()\n",
    "\n",
    "# fit linear regression\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "# score model\n",
    "print(\"Training R2 Score: \", lm.score(X_train, y_train))\n",
    "print(\"Testing R2 Score: \", lm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q24.** Conduct a linear regression on the Boston housing dataset using cross validation. Score your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = boston.drop(columns='MEDV')\n",
    "y = boston['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37406262808038704"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer:\n",
    "lm = LinearRegression()\n",
    "\n",
    "cross_val_score(lm, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.05 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define feature engineering and identify use-cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q25.** Why would you engineer features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "You can engineer features to add variance to your model or to capture the relationship between features that might be significant in prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineer features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q26.** Create a new feature in the boston housing dataset that captures the interaction between the average number of rooms `RM` and the percentage of lower status of the population `LSTAT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "      <th>interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.74350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "      <td>58.68794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "      <td>28.95555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "      <td>20.57412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "      <td>38.09351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO  LSTAT  MEDV  interaction  \n",
       "0     15.3   4.98  24.0     32.74350  \n",
       "1     17.8   9.14  21.6     58.68794  \n",
       "2     17.8   4.03  34.7     28.95555  \n",
       "3     18.7   2.94  33.4     20.57412  \n",
       "4     18.7   5.33  36.2     38.09351  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer:\n",
    "boston['interaction'] = boston['RM'] * boston['LSTAT']\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q27.** Generate polynomial features for the following features in the boston housing dataset:\n",
    "- `CRIM`\n",
    "- `RM`\n",
    "- `AGE`\n",
    "- `LSTAT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "features = ['CRIM', 'RM', 'AGE', 'LSTAT']\n",
    "X = boston[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>CRIM^2</th>\n",
       "      <th>CRIM RM</th>\n",
       "      <th>CRIM AGE</th>\n",
       "      <th>CRIM LSTAT</th>\n",
       "      <th>RM^2</th>\n",
       "      <th>RM AGE</th>\n",
       "      <th>RM LSTAT</th>\n",
       "      <th>AGE^2</th>\n",
       "      <th>AGE LSTAT</th>\n",
       "      <th>LSTAT^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.98</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.041554</td>\n",
       "      <td>0.412064</td>\n",
       "      <td>0.031474</td>\n",
       "      <td>43.230625</td>\n",
       "      <td>428.6900</td>\n",
       "      <td>32.74350</td>\n",
       "      <td>4251.04</td>\n",
       "      <td>324.696</td>\n",
       "      <td>24.8004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>9.14</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.175358</td>\n",
       "      <td>2.154759</td>\n",
       "      <td>0.249613</td>\n",
       "      <td>41.229241</td>\n",
       "      <td>506.6169</td>\n",
       "      <td>58.68794</td>\n",
       "      <td>6225.21</td>\n",
       "      <td>721.146</td>\n",
       "      <td>83.5396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.196079</td>\n",
       "      <td>1.667419</td>\n",
       "      <td>0.109979</td>\n",
       "      <td>51.624225</td>\n",
       "      <td>439.0035</td>\n",
       "      <td>28.95555</td>\n",
       "      <td>3733.21</td>\n",
       "      <td>246.233</td>\n",
       "      <td>16.2409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.226525</td>\n",
       "      <td>1.482546</td>\n",
       "      <td>0.095168</td>\n",
       "      <td>48.972004</td>\n",
       "      <td>320.5084</td>\n",
       "      <td>20.57412</td>\n",
       "      <td>2097.64</td>\n",
       "      <td>134.652</td>\n",
       "      <td>8.6436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>5.33</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>0.493500</td>\n",
       "      <td>3.742510</td>\n",
       "      <td>0.368036</td>\n",
       "      <td>51.079609</td>\n",
       "      <td>387.3674</td>\n",
       "      <td>38.09351</td>\n",
       "      <td>2937.64</td>\n",
       "      <td>288.886</td>\n",
       "      <td>28.4089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>9.67</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.412920</td>\n",
       "      <td>4.327733</td>\n",
       "      <td>0.605632</td>\n",
       "      <td>43.467649</td>\n",
       "      <td>455.5763</td>\n",
       "      <td>63.75431</td>\n",
       "      <td>4774.81</td>\n",
       "      <td>668.197</td>\n",
       "      <td>93.5089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>9.08</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.277052</td>\n",
       "      <td>3.472209</td>\n",
       "      <td>0.411052</td>\n",
       "      <td>37.454400</td>\n",
       "      <td>469.4040</td>\n",
       "      <td>55.56960</td>\n",
       "      <td>5882.89</td>\n",
       "      <td>696.436</td>\n",
       "      <td>82.4464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>5.64</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>0.423862</td>\n",
       "      <td>5.529160</td>\n",
       "      <td>0.342686</td>\n",
       "      <td>48.664576</td>\n",
       "      <td>634.8160</td>\n",
       "      <td>39.34464</td>\n",
       "      <td>8281.00</td>\n",
       "      <td>513.240</td>\n",
       "      <td>31.8096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>6.48</td>\n",
       "      <td>0.012010</td>\n",
       "      <td>0.744554</td>\n",
       "      <td>9.786387</td>\n",
       "      <td>0.710143</td>\n",
       "      <td>46.158436</td>\n",
       "      <td>606.7042</td>\n",
       "      <td>44.02512</td>\n",
       "      <td>7974.49</td>\n",
       "      <td>578.664</td>\n",
       "      <td>41.9904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>7.88</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>0.285882</td>\n",
       "      <td>3.830728</td>\n",
       "      <td>0.373591</td>\n",
       "      <td>36.360900</td>\n",
       "      <td>487.2240</td>\n",
       "      <td>47.51640</td>\n",
       "      <td>6528.64</td>\n",
       "      <td>636.704</td>\n",
       "      <td>62.0944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM     RM   AGE  LSTAT    CRIM^2   CRIM RM  CRIM AGE  CRIM LSTAT  \\\n",
       "0    0.00632  6.575  65.2   4.98  0.000040  0.041554  0.412064    0.031474   \n",
       "1    0.02731  6.421  78.9   9.14  0.000746  0.175358  2.154759    0.249613   \n",
       "2    0.02729  7.185  61.1   4.03  0.000745  0.196079  1.667419    0.109979   \n",
       "3    0.03237  6.998  45.8   2.94  0.001048  0.226525  1.482546    0.095168   \n",
       "4    0.06905  7.147  54.2   5.33  0.004768  0.493500  3.742510    0.368036   \n",
       "..       ...    ...   ...    ...       ...       ...       ...         ...   \n",
       "501  0.06263  6.593  69.1   9.67  0.003923  0.412920  4.327733    0.605632   \n",
       "502  0.04527  6.120  76.7   9.08  0.002049  0.277052  3.472209    0.411052   \n",
       "503  0.06076  6.976  91.0   5.64  0.003692  0.423862  5.529160    0.342686   \n",
       "504  0.10959  6.794  89.3   6.48  0.012010  0.744554  9.786387    0.710143   \n",
       "505  0.04741  6.030  80.8   7.88  0.002248  0.285882  3.830728    0.373591   \n",
       "\n",
       "          RM^2    RM AGE  RM LSTAT    AGE^2  AGE LSTAT  LSTAT^2  \n",
       "0    43.230625  428.6900  32.74350  4251.04    324.696  24.8004  \n",
       "1    41.229241  506.6169  58.68794  6225.21    721.146  83.5396  \n",
       "2    51.624225  439.0035  28.95555  3733.21    246.233  16.2409  \n",
       "3    48.972004  320.5084  20.57412  2097.64    134.652   8.6436  \n",
       "4    51.079609  387.3674  38.09351  2937.64    288.886  28.4089  \n",
       "..         ...       ...       ...      ...        ...      ...  \n",
       "501  43.467649  455.5763  63.75431  4774.81    668.197  93.5089  \n",
       "502  37.454400  469.4040  55.56960  5882.89    696.436  82.4464  \n",
       "503  48.664576  634.8160  39.34464  8281.00    513.240  31.8096  \n",
       "504  46.158436  606.7042  44.02512  7974.49    578.664  41.9904  \n",
       "505  36.360900  487.2240  47.51640  6528.64    636.704  62.0944  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer:\n",
    "# Code from Global Lesson 3.05\n",
    "poly = PolynomialFeatures(include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "pd.DataFrame(X_poly, columns=poly.get_feature_names(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.06 Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the null and alternative hypotheses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q28.** Define the null and alternative hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "The null hypothesis is what you wish to prove wrong. The alternative hypothesis is what you are trying to show and is the opposite of the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a two-sample t-test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q29.** Conduct a two-sample t-test on the following data. Interpret the results at a 0.05 significance level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "trt = np.random.randint(0, 500, 100)\n",
    "ctrl = np.random.randint(0, 500, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value:  0.42235751226105556\n"
     ]
    }
   ],
   "source": [
    "# Answer:\n",
    "# Code from global lesson 3.06\n",
    "t_stat, p_value = stats.ttest_ind(trt, ctrl, equal_var=False)\n",
    "\n",
    "print(\"P-value: \", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Results of t-test:**  \n",
    "Since our p-value is greater than our significance level, we fail to reject the null hypothesis that there is no significant difference between the means of the treatment and control groups. There is no evidence to say that the means between these two groups is significantly different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the t-statistics and p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q30.** Define p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "The p-value is the probability of observing a value at least as extreme due to random chance assuming the null hypothesis is true. To read more about this, check out this [awesome blog post](https://medium.com/@scottrosengrants/p-value-explained-4b1a26edf387) on this topic by a past DSI Denver student!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the steps of hypothesis testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q31.** List the steps of hypothesis testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**  \n",
    "1. Construct the null and alternative hypotheses\n",
    "2. Specify the significance level\n",
    "3. Calculate the test statistic\n",
    "4. Find the p-value and make a conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carry out and understand the results of t-tests on OLS regression slopes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q32.** Carry out the results of the t-test on a linear regression for the boston housing dataset. Interpret the significance of the `CRIM` and `AGE` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noellebrown/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = boston.drop(columns='MEDV')\n",
    "# add constant for statsmodels\n",
    "X = sm.add_constant(X)\n",
    "y = boston['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>MEDV</td>       <th>  R-squared:         </th> <td>   0.804</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.798</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   154.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 02 Apr 2020</td> <th>  Prob (F-statistic):</th> <td>1.95e-164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:55:06</td>     <th>  Log-Likelihood:    </th> <td> -1428.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   2885.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   492</td>      <th>  BIC:               </th> <td>   2944.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>       <td>    7.5486</td> <td>    4.974</td> <td>    1.517</td> <td> 0.130</td> <td>   -2.225</td> <td>   17.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRIM</th>        <td>   -0.1636</td> <td>    0.028</td> <td>   -5.744</td> <td> 0.000</td> <td>   -0.220</td> <td>   -0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZN</th>          <td>    0.0269</td> <td>    0.012</td> <td>    2.237</td> <td> 0.026</td> <td>    0.003</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INDUS</th>       <td>    0.0505</td> <td>    0.054</td> <td>    0.942</td> <td> 0.346</td> <td>   -0.055</td> <td>    0.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHAS</th>        <td>    2.1022</td> <td>    0.751</td> <td>    2.800</td> <td> 0.005</td> <td>    0.627</td> <td>    3.577</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NOX</th>         <td>  -15.4547</td> <td>    3.324</td> <td>   -4.649</td> <td> 0.000</td> <td>  -21.987</td> <td>   -8.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>          <td>    7.9924</td> <td>    0.489</td> <td>   16.347</td> <td> 0.000</td> <td>    7.032</td> <td>    8.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AGE</th>         <td>    0.0151</td> <td>    0.012</td> <td>    1.315</td> <td> 0.189</td> <td>   -0.007</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>         <td>   -1.1186</td> <td>    0.176</td> <td>   -6.363</td> <td> 0.000</td> <td>   -1.464</td> <td>   -0.773</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RAD</th>         <td>    0.3135</td> <td>    0.058</td> <td>    5.444</td> <td> 0.000</td> <td>    0.200</td> <td>    0.427</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TAX</th>         <td>   -0.0121</td> <td>    0.003</td> <td>   -3.699</td> <td> 0.000</td> <td>   -0.019</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO</th>     <td>   -0.7101</td> <td>    0.115</td> <td>   -6.170</td> <td> 0.000</td> <td>   -0.936</td> <td>   -0.484</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>       <td>    1.8930</td> <td>    0.190</td> <td>    9.941</td> <td> 0.000</td> <td>    1.519</td> <td>    2.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>interaction</th> <td>   -0.4290</td> <td>    0.033</td> <td>  -13.196</td> <td> 0.000</td> <td>   -0.493</td> <td>   -0.365</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>229.305</td> <th>  Durbin-Watson:     </th> <td>   1.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2731.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.646</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>13.895</td>  <th>  Cond. No.          </th> <td>1.33e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.33e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   MEDV   R-squared:                       0.804\n",
       "Model:                            OLS   Adj. R-squared:                  0.798\n",
       "Method:                 Least Squares   F-statistic:                     154.9\n",
       "Date:                Thu, 02 Apr 2020   Prob (F-statistic):          1.95e-164\n",
       "Time:                        11:55:06   Log-Likelihood:                -1428.4\n",
       "No. Observations:                 506   AIC:                             2885.\n",
       "Df Residuals:                     492   BIC:                             2944.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "const           7.5486      4.974      1.517      0.130      -2.225      17.322\n",
       "CRIM           -0.1636      0.028     -5.744      0.000      -0.220      -0.108\n",
       "ZN              0.0269      0.012      2.237      0.026       0.003       0.051\n",
       "INDUS           0.0505      0.054      0.942      0.346      -0.055       0.156\n",
       "CHAS            2.1022      0.751      2.800      0.005       0.627       3.577\n",
       "NOX           -15.4547      3.324     -4.649      0.000     -21.987      -8.923\n",
       "RM              7.9924      0.489     16.347      0.000       7.032       8.953\n",
       "AGE             0.0151      0.012      1.315      0.189      -0.007       0.038\n",
       "DIS            -1.1186      0.176     -6.363      0.000      -1.464      -0.773\n",
       "RAD             0.3135      0.058      5.444      0.000       0.200       0.427\n",
       "TAX            -0.0121      0.003     -3.699      0.000      -0.019      -0.006\n",
       "PTRATIO        -0.7101      0.115     -6.170      0.000      -0.936      -0.484\n",
       "LSTAT           1.8930      0.190      9.941      0.000       1.519       2.267\n",
       "interaction    -0.4290      0.033    -13.196      0.000      -0.493      -0.365\n",
       "==============================================================================\n",
       "Omnibus:                      229.305   Durbin-Watson:                   1.210\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2731.179\n",
       "Skew:                           1.646   Prob(JB):                         0.00\n",
       "Kurtosis:                      13.895   Cond. No.                     1.33e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.33e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.OLS(y, X).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Interpretation:**  \n",
    "- `CRIM`: This features has a statistically significant impact on predicting `MEDV`\n",
    "- `AGE`: This features does not have a statistically significant impact on predicting our target and can probably be dropped."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
